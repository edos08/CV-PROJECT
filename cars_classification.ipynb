{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline\n",
    "\n",
    "Data is hierarchically organized as follows: 'root/make_id/model_id/released_year/image_name.jpg'. Root is the 'image' folder of the CompCars dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# from custom files\n",
    "from dataset import CompCarsImageFolder\n",
    "from models import BasicBlock, BottleneckBlock, ResNet, resnet_cfg\n",
    "from models import train, validate\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set root to the image folder of CompCars dataset\n",
    "# root = 'data/image'  # TODO: ADAPT TO YOUR FOLDER STRUCTURE\n",
    "root = '../cars_data/data/image'\n",
    "\n",
    "\n",
    "### Hyperparam configuration\n",
    "params = {                  ## Training Params (taken from original resnet paper: https://arxiv.org/pdf/1512.03385)\n",
    "    'epoch_num': 10,        # number of epochs\n",
    "    'lr': 1e-1,             # Learning Rate\n",
    "    'weight_decay': 1e-4,   # L2 Penalty\n",
    "    'batch_size': 256,      # batch size\n",
    "    'momentum': 0.9,\n",
    "    \n",
    "    'hierarchy': 0,         # Choose 0 for manufacturer classification, 1 for model classifciation\n",
    "    'val_split': 0.2,        # Fraction of validation holdout\n",
    "    \n",
    "    'resnet': resnet_cfg['resnet18']  # Resnet model used\n",
    "}\n",
    "\n",
    "### Device\n",
    "if torch.cuda.is_available():\n",
    "    params[\"device\"] = torch.device(\"cuda\")   # option for NVIDIA GPUs\n",
    "elif torch.backends.mps.is_available():\n",
    "    params[\"device\"] = torch.device(\"mps\")    # option for Mac M-series chips (GPUs)\n",
    "else:\n",
    "    params[\"device\"] = torch.device(\"cpu\")    # default option if none of the above devices are available\n",
    "\n",
    "print(\"Device: {}\".format(params[\"device\"]))\n",
    "\n",
    "### Transforms\n",
    "# TODO: Adapt transforms to our data set\n",
    "# TODO: maybe use v2 transforms: https://pytorch.org/vision/stable/transforms.html\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # TODO: find normalization for CompCars dataset\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # TODO: find normalization for CompCars dataset\n",
    "        ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperDataset:\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "def train_val_dataset(dataset, val_split=params['val_split']):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save total CompCars dataset in a DataFolder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchy=0 -> manufacturer classification; hierarchy=1 -> model classification\n",
    "total_set = CompCarsImageFolder(root, hierarchy=params['hierarchy'])  # Adjust hierarchy as needed\n",
    "print(total_set.classes)\n",
    "print(len(total_set.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = train_val_dataset(total_set)\n",
    "\n",
    "wrapped_datasets = {\n",
    "    'train': WrapperDataset(datasets['train'], transform=data_transforms['train']),\n",
    "    'val': WrapperDataset(datasets['val'], transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(wrapped_datasets['train'], batch_size=params['batch_size'], shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(wrapped_datasets['val'], batch_size=params['batch_size'], shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "print(f\"Total dataset size: {len(total_set)}\")\n",
    "print(f\"Training dataset size: {len(datasets['train'])}\")\n",
    "print(f\"Validation dataset size: {len(datasets['val'])}\")\n",
    "\n",
    "x, y = next(iter(dataloaders['train']))\n",
    "print(f\"Batch of images shape: {x.shape}\")\n",
    "print(f\"Batch of labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up resnet model\n",
    "resnet = ResNet(params['resnet']['block'], params['resnet']['layers'], \n",
    "                len(total_set.classes)).to(params['device'])\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD( #SGD used in original resnet paper\n",
    "    resnet.parameters(), \n",
    "    lr=params['lr'], \n",
    "    weight_decay=params['weight_decay'], \n",
    "    momentum=params['momentum']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Loops\n",
    "train_losses, validation_losses, train_acc, validation_acc = list(), list(), list(), list()\n",
    "\n",
    "# Just some fancy progress bars\n",
    "pbar_epoch = trange(params[\"epoch_num\"], desc=\"Training\")\n",
    "pbar_inside_epoch = tqdm(total = (len(dataloaders['train'])+len(dataloaders['val'])), desc=\"Training and validation per epoch\", position=1, leave=True)\n",
    "\n",
    "# Stop the training phase in case there is no improvement\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=0.1)\n",
    "\n",
    "for epoch in pbar_epoch:\n",
    "    pbar_inside_epoch.reset()\n",
    "    \n",
    "    train_results = train(dataloaders['train'], resnet, epoch, criterion, optimizer, params[\"device\"], pbar=pbar_inside_epoch)\n",
    "    train_losses.append(train_results[0])\n",
    "    train_acc.append(1 - train_results[1])\n",
    "    \n",
    "    validation_results = validate(dataloaders['val'], resnet, epoch, criterion, params[\"device\"], pbar=pbar_inside_epoch)\n",
    "    validation_losses.append(validation_results[0])\n",
    "    validation_acc.append(1 - validation_results[1])\n",
    "    \n",
    "    # Comment on the following lines if you don't want to stop early in case of no improvement\n",
    "    if early_stopper.early_stop(validation_results[0]):\n",
    "        params['epoch_num'] = epoch\n",
    "        print(\"\\n\\nEarly stopping...\")\n",
    "        break\n",
    "\n",
    "pbar_inside_epoch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the performance of the model in the training and validation phase\n",
    "\n",
    "plots = [\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_losses, \"Train Loss\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_losses, \"Validation Loss\")\n",
    "]\n",
    "\n",
    "show_plot(plots, \"Model Loss for Epoch\", \"Epoch\", \"Loss\")\n",
    "\n",
    "plots = [\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), train_acc, \"Train Error\"),\n",
    "    (np.arange(0, params[\"epoch_num\"], 1), validation_acc, \"Validation Error\")\n",
    "]\n",
    "\n",
    "show_plot(plots, \"Model Error for Epoch\", \"Epoch\", \"Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
